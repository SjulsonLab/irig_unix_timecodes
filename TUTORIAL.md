# Tutorial: Decoding IRIG Timecodes with neurokairos-pynapple

## The Problem: Multiple Clocks

Multi-modal neuroscience experiments produce data from independent systems — electrophysiology rigs, video cameras, behavior controllers — each running on its own clock. These clocks drift relative to each other (typically 10–100 ppm), so you can't simply line up timestamps by assuming they started at the same time. To combine these streams in pynapple, you need a common time reference.

IRIG timecodes solve this by embedding a UTC (Coordinated Universal Time) time signal directly into each recording. A dedicated device generates the IRIG signal, which gets recorded alongside neural data on a spare analog channel or displayed as a blinking LED visible to cameras. By decoding the IRIG signal from each recording independently, you anchor every stream to the same UTC reference — clock drift and all.

## What is IRIG?

IRIG-H is a pulse-width-modulated timecode: one pulse per second, each encoding a binary digit. Pulse widths encode bit values: 0.2 seconds = binary 0, 0.5 seconds = binary 1, 0.8 seconds = reference marker. A complete frame is 60 pulses (one minute), with marker pulses at fixed positions acting as delimiters.

Within each frame, the bits encode the current UTC time in BCD (binary-coded decimal): seconds, minutes, hours, day-of-year, and year. Frame boundaries are identified by two consecutive marker pulses — the last pulse of one frame and the first of the next.

In a typical setup, a Raspberry Pi running [NeuroKairos](https://github.com/evilrobotxoxo/irig_unix_timecodes) generates the IRIG signal, which gets split and fed to each recording system. The decoder in neurokairos-pynapple handles real-world issues automatically: noise spikes (extra pulses), signal dropouts (missing pulses), and concatenated files where multiple recording segments are stitched together.

## The Core Abstraction: ClockTable

Every decoder in neurokairos-pynapple produces a `ClockTable` — a sparse mapping between two time domains:

- **source**: values in the recording's native domain (sample indices for electrophysiology, frame indices for video, seconds for pre-extracted intervals)
- **reference**: UTC time in Unix format (the number of seconds since Jan. 1, 1970) when the corresponding source value was collected

There's roughly one entry per IRIG pulse (~1 per second). Between entries, `np.interp` handles the conversion.

```python
import neurokairos_pynapple as nk

ct = nk.decode_dat_irig("recording.dat", n_channels=3, irig_channel=2)
print(ct)
# ClockTable: 238 entries (samples), rate=30000.0
#   recording: 2025-01-15T14:30:37Z → 2025-01-15T14:34:35Z
#   file: recording.dat (/data/ephys/recording.dat)
#   source=[6000.0..7134000.0], reference=[1736950237.0..1736950475.0]

# Convert sample indices to UTC timestamps
import numpy as np
timestamps = ct.source_to_reference(np.array([30000, 60000, 90000]))

# Convert UTC timestamps back to sample indices
samples = ct.reference_to_source(np.array([1736950240.0, 1736950250.0]))
```

### Metadata and Decoding Quality

Every ClockTable carries a `metadata` dict with provenance, decoding quality, and NTP sync status. Decoders populate this automatically.

```python
ct = nk.decode_dat_irig("recording.dat", n_channels=3, irig_channel=2)

# Provenance — where did this come from?
ct.metadata["source_file"]     # "recording.dat"
ct.metadata["source_path"]     # "/data/ephys/recording.dat"
ct.metadata["n_channels"]      # 3
ct.metadata["irig_channel"]    # 2

# Recording times (ISO 8601 UTC)
ct.metadata["recording_start"]  # "2025-01-15T14:30:37Z"
ct.metadata["recording_stop"]   # "2025-01-15T14:34:35Z"

# Decoding quality — how clean was the signal?
ct.metadata["n_raw_pulses"]     # total pulses detected
ct.metadata["n_extra_removed"]  # noise spikes removed
ct.metadata["n_missing_gaps"]   # gaps from missing pulses
ct.metadata["n_frames_decoded"] # complete IRIG frames decoded
ct.metadata["n_concat_boundaries"]  # concatenation boundaries found
```

**NTP sync status**: If the IRIG signal was generated by NeuroKairos, the decoder extracts chrony NTP sync quality from previously unused bits near the end of each IRIG frame. This tells you how well the IRIG generator was synchronized to UTC:

```python
ct.metadata["stratum"]              # worst-case NTP stratum (1–4; 4 = not synchronized)
ct.metadata["UTC_sync_precision"]   # worst-case root dispersion, e.g. "< 0.25 ms"
```

Stratum 1–2 with sub-millisecond dispersion is typical for a well-configured NeuroKairos setup. Higher stratum or larger dispersion means the IRIG generator's clock was less tightly locked to UTC during the recording. Since these bits are unused in standard IRIG-H, old recordings (without sync status encoding) have all-zero bits — this is ambiguous with genuinely excellent sync (stratum 1, < 0.25 ms).

Metadata persists through `save()`/`load()` — it's serialized as JSON inside the NPZ file.

### Decode Once, Reload Many Times

IRIG decoding is the slow step — it reads the entire recording to find and classify pulses. The resulting ClockTable is small (a few KB). Save it once, reload instantly:

```python
# First time: decode and auto-save (default behavior)
ct = nk.decode_dat_irig("recording.dat", n_channels=3, irig_channel=2)
# → saves recording.dat.clocktable.npz

# Every subsequent time: reload in milliseconds
ct = nk.ClockTable.load("recording.dat.clocktable.npz")
```

All `decode_*` functions auto-save by default (except `decode_intervals_irig`, which has no input file to derive a path from — pass `save="path.npz"` explicitly).

## From ClockTable to Pynapple

### BinaryFile (Convenient Path)

`BinaryFile` wraps a memory-mapped data file and a ClockTable. It produces pynapple `Tsd`/`TsdFrame` objects on demand for arbitrary time segments, without materializing timestamps for the entire recording.

```python
# Auto-loads ClockTable from recording.dat.clocktable.npz
bf = nk.BinaryFile("recording.dat", n_channels=3)

# Extract 10 seconds of data from channel 0
# Times are relative to time_origin (the first decoded UTC timestamp)
data = bf.get(start=10.0, end=20.0, channels=0)   # → pynapple Tsd
data = bf.get(start=10.0, end=20.0)                # → pynapple TsdFrame (all channels)
data = bf.get(start=10.0, end=20.0, channels=[0, 1])  # → TsdFrame (selected channels)

# Extract data for multiple intervals
import pynapple as nap
intervals = nap.IntervalSet(start=[10, 30, 50], end=[20, 40, 60])
data = bf.restrict(intervals, channels=0)           # → pynapple Tsd
```

### Manual Path (Custom Formats)

If your data isn't in a flat binary format, use the ClockTable directly to compute timestamps for whatever data structure you have:

```python
ct = nk.ClockTable.load("recording.dat.clocktable.npz")

# Your custom loading code
my_samples = np.arange(30000, 60000)  # sample indices you care about
my_timestamps = ct.source_to_reference(my_samples.astype(np.float64))

# Build pynapple objects yourself
time_origin = ct.reference[0]
relative_times = my_timestamps - time_origin
tsd = nap.Tsd(t=relative_times, d=my_data)
```

## Decoding vs Synchronization

neurokairos-pynapple uses a two-step model:

1. **Decode** (time-reference): Anchor each recording stream to UTC using IRIG decoding. This corrects clock drift — each ClockTable captures the non-linear mapping between the local clock and UTC. This is what neurokairos-pynapple does.

2. **Synchronize**: Shift time-referenced objects into the same reference frame so their timestamps are directly comparable. This is a simple offset — no drift correction. This is what pynapple's `sync_to()` does.

The distinction matters. Two recordings with the same `time_origin` can be used together directly. Two recordings with different `time_origin` values need `sync_to()` to shift one into the other's frame. But both must be time-referenced first, or the drift makes synchronization meaningless over long recordings.

## Synchronizing Multiple Streams

Here's a complete multi-modal workflow: electrophysiology + video, decoded and synchronized.

```python
import numpy as np
import pynapple as nap
import neurokairos_pynapple as nk

# --- Electrophysiology ---
# Decode IRIG from the ephys recording
ephys_ct = nk.decode_dat_irig("ephys.dat", n_channels=64, irig_channel=63)
ephys = nk.BinaryFile("ephys.dat", n_channels=64)

# --- Video ---
# Decode IRIG from the video (LED visible in a small ROI)
video_ct = nk.decode_video_irig("behavior.avi", roi=(10, 20, 10, 20), fps=30.0)

# Build a pynapple Tsd from video data (e.g., extracted tracking coordinates)
# Frame indices → UTC timestamps via the video ClockTable
frame_indices = np.arange(len(x_positions), dtype=np.float64)
frame_utc = video_ct.source_to_reference(frame_indices)
video_origin = video_ct.reference[0]
video_times = frame_utc - video_origin

tracking = nap.Tsd(t=video_times, d=x_positions).set_time_origin(video_origin)

# --- Synchronize video to ephys reference frame ---
tracking_synced = tracking.sync_to(ephys)

# Now ephys.get() and tracking_synced share the same time reference
lfp = ephys.get(start=100.0, end=110.0, channels=0)
# tracking_synced timestamps are in the same frame — directly comparable
```

## Data Format Reference

### Interleaved .dat Files

For flat binary files with interleaved int16 channels (e.g., from Open Ephys, Intan).

```python
ct = nk.decode_dat_irig(
    dat_path,       # path to the .dat file
    n_channels,     # total number of interleaved channels
    irig_channel,   # zero-based index of the IRIG channel
    save=True,      # save to <dat_path>.clocktable.npz (default True)
)

bf = nk.BinaryFile(
    dat_path,        # same .dat file
    n_channels,      # same channel count
    clock_table=None,  # auto-loads from <dat_path>.clocktable.npz
    dtype="int16",     # data type (default int16)
)
```

### SpikeGLX Files

For SpikeGLX `.bin` files. Reads `nSavedChans` and sample rate from the paired `.meta` file automatically.

```python
ct = nk.decode_sglx_irig(
    bin_path,         # path to the .bin file (.meta must exist alongside)
    irig_channel,     # zero-based channel index, or "sync" for the last channel
    save=True,        # save to <bin_path>.clocktable.npz (default True)
)

# BinaryFile.from_sglx reads nSavedChans from .meta automatically
bf = nk.BinaryFile.from_sglx(
    bin_path,         # path to the .bin file
    clock_table=None,   # auto-loads from <bin_path>.clocktable.npz
)
```

The `"sync"` shortcut resolves to the last saved channel — this is where SpikeGLX stores the sync/digital word, which is the typical IRIG channel for nidq streams.

### Video Files

For video files with a visible IRIG LED. Requires `opencv-python`.

```python
ct = nk.decode_video_irig(
    video_path,     # path to the video file (AVI, MP4, etc.)
    roi,            # (row_start, row_end, col_start, col_end) for the LED region
    fps=None,       # optional expected fps — warns if auto-estimate differs by >5%
    save=True,      # save to <video_path>.clocktable.npz (default True)
)
```

The `roi` defines the pixel region containing the IRIG LED. Pick a small rectangle tightly around the LED — a few pixels is enough. The decoder extracts mean grayscale brightness per frame from this region, then runs the standard IRIG pipeline on the resulting brightness signal.

To choose an ROI, open the video in any viewer, note the LED coordinates, and pass them as `(row_start, row_end, col_start, col_end)`. Rows are y (top to bottom), columns are x (left to right).

**Dropped frame diagnostics:**

```python
from neurokairos_pynapple.video import dropped_frame_report

report = dropped_frame_report(ct, expected_fps=30.0)
print(f"Dropped {report['total_dropped']} of {report['total_expected']} frames")
print(f"Seconds with drops: {report['seconds_with_drops']}")
```

### Pre-extracted Pulse Intervals

For when you already have pulse onset/offset times (e.g., from Open Ephys event files, TTL loggers, or camera event CSVs).

```python
# From arrays of onset and offset times (in seconds)
ct = nk.decode_intervals_irig(
    onsets,            # 1-D array of pulse onset times
    offsets=offsets,   # 1-D array of pulse offset times (required for arrays)
    source_units="seconds",  # label for the source axis (default "seconds")
    save="output.clocktable.npz",  # explicit path (no auto-save — no input file to derive from)
)

# From a pynapple IntervalSet (or any object with .start/.end attributes)
intervals = nap.IntervalSet(start=onsets, end=offsets)
ct = nk.decode_intervals_irig(intervals, save="output.clocktable.npz")
```

## ClockTable Persistence

Every decoder saves its ClockTable alongside the input file by default:

| Decoder | Auto-save path |
|---|---|
| `decode_dat_irig` | `<dat_path>.clocktable.npz` |
| `decode_sglx_irig` | `<bin_path>.clocktable.npz` |
| `decode_video_irig` | `<video_path>.clocktable.npz` |
| `decode_intervals_irig` | No auto-save — pass `save="path.npz"` |

Reload with `ClockTable.load()`:

```python
ct = nk.ClockTable.load("recording.dat.clocktable.npz")
```

`BinaryFile` auto-loads from `<dat_path>.clocktable.npz` when no `clock_table` argument is passed.

## BinaryFile Reference

```python
bf = nk.BinaryFile("recording.dat", n_channels=3)

# Properties
bf.n_samples          # total samples in file
bf.n_channels         # number of channels
bf.clock_table        # the ClockTable
bf.dtype              # numpy dtype (e.g., int16)
bf.time_origin        # UTC timestamp of t=0 (float)
bf.duration           # total duration in seconds
bf.time_range         # (start, end) in seconds relative to time_origin
bf.segment_boundaries # indices where concatenation boundaries occur

# Data extraction (times relative to time_origin)
bf.get(start, end, channels=None)       # → Tsd (single int) or TsdFrame
bf.restrict(interval_set, channels=None)  # → Tsd or TsdFrame for multiple intervals

# Time origin management
bf2 = bf.set_time_origin(new_origin)    # new BinaryFile sharing same data
bf2 = bf.sync_to(other)                # set_time_origin(other.time_origin)
```

`get()` validates that the constant-rate assumption holds within the requested segment (warns if clock drift exceeds 0.5 ms). It raises `ValueError` if the segment spans a concatenation boundary — use `restrict()` with intervals that avoid boundaries, or call `get()` separately for each segment.
